---
layout: post
title: "概率图模型"
tags: dm
category: note
---

**概率图模型**是用图形模式表达基于概率相关关系的模型的总称。概率图模型结合概率论与图论，利用图来表示与模型有关的变量的联合概率分布。

## 高维随机变量

概率图模型研究**高维随机变量**：$P(x_1, x_2, \cdots, x_p)$.

随机变量的两个基本问题：

1. 边缘概率
2. 条件概率

**加法法则**——边缘概率：

$$
p(X)=\sum_Yp(X,Y)
$$

**乘法法则**——条件概率

$$
p(X, Y) = p(X|Y)p(Y) = p(Y|X)p(X)
$$

**链式法则**：

$$
p(x_1, x_2, \cdots, x_p)=p(x_1)\prod_{i=2}^pp(x_i|x_1, x_2, \cdots, x_{i-1})
$$

**贝叶斯法则**：

$$
p(x_2|x_1)=\frac{p(x_1, x_2)}{p(x_1)}=\frac{p(x_1, x_2)}{\sum_{x_2}p(x_1, x_2)}=\frac{p(x_1|x_2)p(x_2)}{\sum_{x_2}p(x_1, x_2)}
$$

使用高维随机变量的缺点：计算量巨大。

解决方法：对高维随机变量进行简化。

- 朴素贝叶斯算法

    假设1：假设维度之间相互独立，彼此之间互不相干。典型的算法：朴素贝叶斯算法，假设各个维度相互独立。

    $$
    p(x_1, x_2, \cdots, x_p)=\prod_{i=1}^pp(x_i)
    $$
    
    缺陷：过于简化

- 马尔科夫假设

    假设2：假设当前状态只与前一个状态有关，其他状态无关，即马尔可夫假设。
    
    $$
    X_j \bot X_{i+1} | X_i, \quad j < i
    $$

    缺陷：一个状态往往跟前面多个状态相关

- 条件独立假设

    假设3：将所有变量分为三个互不相交的集合$A, B, C$,得到条件独立性假设：

    $$
    X_A\bot X_B | X_V
    $$

    概率图研究问题：高维随机变量。

    解决方法：条件独立性假设

## 贝叶斯网络

**贝叶斯网络**（信念网络或有向无环图模型）是一种概率图模型。模拟人类推理过程中因果关系的不确定性模型，其网络拓扑结构是一个有向无环图，把某个研究系统中涉及的随机变量，根据是否条件独立绘制在一个有向图中，形成贝叶斯网络。

在贝叶斯网络中，

- **节点**：表示随机变量$\{X_1, X_2, \cdots, X_n\}$，即可观察到的变量、隐变量、未知参数等。
- **边**：节点间有因果关系或非条件独立的变量或命题用箭头连接。
- **权值**：两个节点之间用单箭头连接，两节点产生条件概率值。

假设节点$E$直接影响到节点$H$，即$E\rightarrow H$，则用从$E$指向$H$的箭头建立节点$E$到节点$H$的**有向弧 $(E, H)$，权值为条件概率$P(H\|E)$. 

令$G=(L, E)$表示一个有向无环图 (DAG). 

- $L$表示图形中的所有节点的集合。
- $E$表示有向连接线段的集合。
- $X_i(i\in L)$为有向无环图中的某一个节点$i$所代表的的随机变量。
- 若所有节点$X=\{X_i\}$的联合概率可以表示成：

    $$
    P(x) = \prod_{i\in I}p(x_i|x_{pa(i))}
    $$
    
    则称$X$为相对于**有向无环图$G$的贝叶斯网络**，其中$pa(i)$表示节点$i$的父节点集合。

![Bayesian Network](/assets/dm_24.png)

- 链式法则：$p(x_1, x_2, \cdots, x_k)=p(x_1)p(x_2\|x_1)\cdots p(x_k\|x_1, \cdots, x_{k-1})$

- 因子分解：$p(x_1, x_2, \cdots, x_p) = \prod_{i=1}^pp(x_i\|x_{pa(i)})$

依据条件独立性：

$$
X_A\bot X_B | X_C
$$

得到因子分解：

$$
p(x_1, x_2, \cdots, x_p) = \prod_{i=1}^p p(x_i | x_{pa(i)})
$$

### 贝叶斯网络典型拓扑结构

- **tail-tail**

    ![t2t](/assets/dm_25.png)
    
    在tail-tail拓扑结构中，若$a$被观察，则路径堵塞，$b$和$c$相互独立。
    
    $$
    p(c, b|a)=p(c|a)p(b|a)
    $$
    
- **head-tail**

    ![h2t](/assets/dm_26.png)

    在head-tail拓扑结构中，若$b$被观察，则路径堵塞，$a$和$c$相互独立。

    $$
    p(c|b)=p(c|a, b)
    $$

- **head-head**

    ![h2h](/assets/dm_27.png)
    
    在head-head拓扑结构中，若$c$未被观察，则路径堵塞，$a$和$b$相互独立。*一旦$c$或$c$的后续结点被观察，那么两者的独立性被打破。*
    
- **D划分**：判断贝叶斯网络中任意两个结点是否独立。D划分是对三种基本拓扑结构的推广。

    给定证据节点集合$C$，变量$a, b$独立，当满足以下条件：
    
    - 任一连接$a$和$b$的tail-tail和head-tail无向路径中，至少有一个节点在$C$中。
    - 任一连接$a$和$b$的head-head无向路径中，没有节点在$C$中。

    ![d-partition](/assets/dm_28.png)


### 隐马尔科夫链

**隐马尔科夫链**：即符合马尔科夫假设的贝叶斯网络，包含一层隐状态和一层观察值。一个隐状态序列产生一个观察值序列，每个隐状态依赖于前一个隐状态。

![markov chain](/assets/dm_33.png)

HMM模型参数：

- 状态种类数量$K$，观察值种类数量$M$
- 每种状态作为初始状态的概率$\boldsymbol\pi$（$K$维向量）
- 状态之间的转移概率$\boldsymbol A$（$K\times K$矩阵）
- 状态到观察值的发射概率$\boldsymbol B$（$K\times M$矩阵）

HMM的三个问题：

1. 估计问题：给定观察序列$x_1, x_2, \cdots, x_n$和模型参数$(\boldsymbol\pi, \boldsymbol A, \boldsymbol B)$，观察序列的概率有多大？【估计】
2. 序列问题：给定观察序列$x_1, x_2, \cdots, x_n$和模型参数$(\boldsymbol\pi,  \boldsymbol A,\boldsymbol B)$，最可能的状态序列是什么？【推理】
3. 训练问题：给定观察序列$x_1, x_2, \cdots, x_n$，最佳的模型参数$(\boldsymbol\pi,\boldsymbol A,\boldsymbol B)$是什么？【学习】
